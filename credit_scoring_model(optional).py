# -*- coding: utf-8 -*-
"""credit_scoring_model(optional).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Yi2iy1Ichgg_TEk8lygZfXMHYhdqhwM

#Imports
"""

!pip install pycaret
!pip install catboost

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, GridSearchCV
from imblearn.over_sampling import RandomOverSampler
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve
import pycaret
from pycaret.classification import ClassificationExperiment

!git clone https://github.com/vassert32/credit_scoring

"""#Data Understanding"""

df = pd.read_csv("/content/credit_scoring/data/raw/bank.csv", delimiter=";")
df

print(df.isnull().sum())
df.info()

df.describe(include='all')

objects_df = df.select_dtypes(include=['object']).columns
for column in objects_df:
    print(f"Unique objects of {column}: {df[column].unique()}")

"""#  Hypotheses

Вот 10 возможных гипотез по представленным данным для задачи кредитного скоринга:

### 1. **Возраст заемщика влияет на вероятность дефолта**:
   - Гипотеза: Молодые заемщики (например, до 25 лет) или пожилые заемщики (например, старше 60 лет) чаще сталкиваются с финансовыми трудностями и могут не справиться с выплатами по кредиту.

### 2. **Заемщики с высоким уровнем образования реже попадают в дефолт**:
   - Гипотеза: Люди с высоким уровнем образования, как правило, имеют более высокую заработную плату и финансовую стабильность, что снижает вероятность дефолта.

### 3. **Семейное положение влияет на кредитоспособность**:
   - Гипотеза: Люди, состоящие в браке, чаще имеют более стабильные финансовые обязательства и более ответственны по отношению к выплатам по кредитам, чем одинокие заемщики.

### 4. **Заемщики, которые уже были в дефолте, более склонны к повторному дефолту**:
   - Гипотеза: Если заемщик уже имеет историю дефолта, он будет более склонен к повторению такого поведения.

### 5. **Больший баланс на счете заемщика ассоциируется с более низким риском дефолта**:
   - Гипотеза: Заемщики с высоким балансом на своих счетах имеют больше средств для погашения долгов, и, следовательно, они менее склонны к дефолту.

### 6. **Наличие жилья снижает риск дефолта**:
   - Гипотеза: Заемщики, владеющие недвижимостью, менее склонны к дефолту, поскольку у них есть дополнительное обеспечение и активы.

### 7. **Сумма кредита влияет на вероятность дефолта**:
   - Гипотеза: Чем выше сумма кредита, тем выше вероятность того, что заемщик может оказаться в затруднительном положении и не сможет своевременно погасить долг.

### 8. **Способ связи с заемщиком может влиять на риск дефолта**:
   - Гипотеза: Заемщики, которые предпочитают связь через электронную почту, могут быть менее склонны к дефолту, чем те, кто предоставляет только телефонные номера.

### 9. **Частота взятия кредитов в прошлом (кампания) увеличивает риск дефолта**:
   - Гипотеза: Люди, которые часто берут кредиты, могут быть менее финансово ответственными или находиться в сложном финансовом положении, что увеличивает вероятность дефолта.

### 10. **Результат предыдущей маркетинговой кампании (poutcome) влияет на результат текущей кампании (y)**:
   - Гипотеза: Если в предыдущей кампании клиент отказался от предложения банка или не смог выплатить кредит, то он, вероятно, откажется или попадет в дефолт в текущей кампании.

### Дополнительные гипотезы:

- **Продолжительность займа (duration)**: Кредиты с более длительным сроком могут быть более рискованными, поскольку у заемщика больше времени для изменения финансового положения.
- **Месяц взятия кредита (month)**: Сезонные колебания могут влиять на вероятность дефолта. Например, в конце года у заемщиков может быть больше расходов (праздники, отпуск), что может повысить вероятность дефолта.

Каждая из этих гипотез может быть проверена с помощью статистического анализа или машинного обучения, анализируя, как определенные переменные влияют на целевую переменную (например, дефолт или нет).

#Exploratory Data Analysis
"""

y_counts = df['y'].value_counts()
print(y_counts)
labels = y_counts.index
sizes = y_counts.values

colors = ['lightcoral', 'lightskyblue']

plt.pie(sizes, labels=labels, colors=colors, autopct='%.1f%%', startangle=140)
plt.axis('equal')
plt.title('% of Loan Approval')
plt.show()

categorical_df = []
for col in df.columns:
    if df[col].nunique()<10:
        categorical_df.append(col)

print(f'categ numericals columns are {categorical_df}')

df.groupby('y')['age'].median()

df.groupby('y')['age'].mean() # разница почти 2 года

fig = plt.figure(figsize=[16,12])
fig.suptitle('Количественный график категориальных признаков', fontsize=18, fontweight='bold')
fig.subplots_adjust(top=0.92);
fig.subplots_adjust(hspace=0.5, wspace=0.4);
for i , columns in enumerate(categorical_df):
    input = np.unique(df[columns] , return_counts = True)
    col= 'input'
    ax1 = fig.add_subplot(2, 4, i+1);
    ax1 = sns.barplot(x=list(eval(f'{col}[0]')), y=list(eval(f'{col}[1]')))
    ax1.set_title(f'{columns}')
    ax1.set_xlabel(f'{columns}')
    ax1.set_ylabel('Количество')
    ax1.bar_label(ax1.containers[0])

numerical_df = df.select_dtypes(include=['int64', 'float64'])
print(numerical_df.columns)

fig = plt.figure(figsize=(16, 8))
fig.suptitle('Плотность числовых признаков', fontsize=18, fontweight='bold')
fig.subplots_adjust(top=0.92)
fig.subplots_adjust(hspace=0.5, wspace=0.4)

for i, column in enumerate(numerical_df.columns):
    ax = fig.add_subplot(2, 4, i + 1)
    sns.kdeplot(data=numerical_df, x=column, fill=True, ax=ax)
    ax.set_title(f'График плостности {column}')
    ax.set_xlabel(column)
    ax.set_ylabel('Плотность')
plt.show()

"""следущий график мы нормализовали относительно их количества в датасете, это нам покажет что больше повлияет на обучение модели, и каких больше всего признаков."""

educ_def = (df.groupby(['default'])["education"].value_counts(normalize=True).rename("aboba").mul(100).reset_index().sort_values('education'))
sns.barplot(x='education', y='aboba', hue='default', data=educ_def)
plt.title('В процентах')
plt.xlabel('Default')
plt.ylabel('Count')
plt.show()

categorical_df = df.select_dtypes(include=['object'])   # выбираем столбцы объектов (категориальные данне)
categorical_df.drop(['y'], axis=1, inplace=True)        # убираем столбец loan aproval (так как по нему мы стакаем)

categorical_cols_to_keep = []
for col in categorical_df.columns:
    if len(categorical_df[col].unique()) < 10:          # берем только столбцы с менее чем 10 уникальными знаечниями
        categorical_cols_to_keep.append(col)

categorical_df = categorical_df[categorical_cols_to_keep]

fig, axes = plt.subplots(3, 3, figsize=(16, 10))    # создаем 9 графиков на поле размеров 16 на 10 дюймов
fig.suptitle('Составные гистограммы категориальных признаков по признаку loan approval', fontsize=18, fontweight='bold')
fig.subplots_adjust(top=0.92)                       # отступ от верхней границы
fig.subplots_adjust(hspace=0.5, wspace=0.4)         # отступ между графиками

# проходим по столбцам и создаем стаканые barplot'ы по признаку "y"
for i, column in enumerate(categorical_df.columns):
    ax = axes[i // 3, i % 3]

    crosstab = pd.crosstab(df[column], df['y'])         # кросс таблица количества значений признаков по столбцу 'y'

    proportions = crosstab.div(crosstab.sum(1), axis=0) # расчет пропорции в процентном соотношении (деление всех признаков на сумму строки)

    # составная гистограмма
    ax.bar(proportions.index, proportions['yes'], label='Yes', color='g')   # отрисовка количества "yes"
    ax.bar(proportions.index, proportions['no'], label='No', bottom=proportions['yes'], color='r')  # отрисовка "no" от конца "yes"

    ax.set_title(f'Bar plots {column} по признаку loan approval')
    ax.set_xlabel(column)
    ax.set_ylabel('Пропорция')
    ax.legend()

plt.show()

house = (df.groupby(['default'])["housing"].value_counts(normalize=True).rename("counts %%%").mul(100).reset_index())
sns.barplot(x='housing', y='counts %%%', hue='default', data=house)

fig = plt.figure(figsize=(14, 8))
fig.suptitle('График плотности числовых характеристик', fontsize=18, fontweight='bold')
fig.subplots_adjust(top=0.92)
fig.subplots_adjust(hspace=0.5, wspace=0.4)

# цикл по числовым характеристикам и составление kde графиков по признаку 'y' - loan approval
for i, column in enumerate(numerical_df.columns):
    ax = fig.add_subplot(2, 4, i + 1)
    sns.kdeplot(data=df[df['y'] == 'no'][column], color="Red", shade=True, label="Not Approval")
    sns.kdeplot(data=df[df['y'] == 'yes'][column], color="Blue", shade=True, label="Approval")
    ax.set_title(f'Density Plot of {column}')
    ax.set_xlabel(column)
    ax.set_ylabel('Density')
    ax.legend()

plt.show()

plt.figure(figsize=(15,7))
work_def = (df.groupby(['default'])["job"].value_counts(normalize=True).rename("percent").mul(100).reset_index())
sns.barplot(x='job', y='percent', hue='default', data=work_def)
plt.title('в процентах')

"""#Preprocessing"""

object_columns_with_unknown = []
for column in df.columns:
    if 'unknown' in df[column].values:
        object_columns_with_unknown.append(column)
print(object_columns_with_unknown)
# замена пустых значений NaN'ами
df[object_columns_with_unknown] = df[object_columns_with_unknown].replace('unknown', np.nan)

# инициализация импутра для заоплнения пустых значений на моду (самое частое)
categorical_imputer = SimpleImputer(strategy='most_frequent')

# применение импутера - он не пригодился отмена
#df = categorical_imputer.fit_transform(df.select_dtypes(include=['object']))

# еще раз проверка уникальных значений
for column in object_columns_with_unknown:
    unique_values = df[column].unique()
    print(f'Unique values for column {column}: {unique_values}')

"""#Encoding Categorical Data"""

# преобразование категориальных данных лейбл энкодингом
def object_to_int(dataframe_series):
    if dataframe_series.dtype=='object':
        dataframe_series = LabelEncoder().fit_transform(dataframe_series)
    return dataframe_series

df = df.apply(lambda x: object_to_int(x))
df.info()

df.head()

"""#Detect and Reduce Outliers"""

numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']

# создание сабплотов для отображения графиков 3х3
num_rows = 2
num_cols = 4
fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 10))

# сглаживание массива осей для простого перебора
axes = axes.flatten()

# проход цикла по категориальным данным и создаем боксплоты
for i, col in enumerate(numerical_columns):
    sns.boxplot(x='y', y=col, data=df, ax=axes[i])
    axes[i].set_title(f'Boxplot for {col}')
    if i >= len(numerical_columns):
        fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

# очистка данных от выбросом квантилями
def remove_outliers_iqr(data, numeric_columns, threshold=1.5):
    Q1 = data[numeric_columns].quantile(0.10)
    Q3 = data[numeric_columns].quantile(0.90)
    IQR = Q3 - Q1

    # строки с выбросами
    outlier_rows = ((data[numeric_columns] < (Q1 - threshold * IQR)) | (data[numeric_columns] > (Q3 + threshold * IQR))).any(axis=1)
    # удаление этих строк
    cleaned_data = data[~outlier_rows]

    return cleaned_data

cleaned_dataset = remove_outliers_iqr(df, numerical_columns)
df = pd.DataFrame(cleaned_dataset)
df.info()

"""# Normalize Data"""

scaler = RobustScaler()
df1 = df[numerical_columns]
df2 = df.drop(numerical_columns,axis=1)
robust_df = scaler.fit_transform(df1)
robust_df = pd.DataFrame(robust_df, columns=numerical_columns)
df2 = pd.DataFrame(df2)
robust_df.reset_index(drop=True, inplace=True)
df2.reset_index(drop=True, inplace=True)
df_merges = pd.concat([robust_df, df2], axis=1)
df_merges.info()

df_merges.head()

numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']

# создание сабплотов для отображения графиков 3х3
num_rows = 2
num_cols = 4
fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 10))

# сглаживание массива осей для простого перебора
axes = axes.flatten()

# проход цикла по категориальным данным и создаем боксплоты
for i, col in enumerate(numerical_columns):
    sns.boxplot(x='y', y=col, data=df_merges, ax=axes[i])
    axes[i].set_title(f'Boxplot for {col}')
    if i >= len(numerical_columns):
        fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

"""#One Hot Encoding"""

# кодированние one-hot данных, которые были категориальными
one_hot_data = pd.get_dummies(df_merges, columns = ['poutcome','education','marital','month','job'])

one_hot_data.head()

"""#Modeling"""

# деление датасета по loan approval
X= one_hot_data.drop('y',axis=1)
y= one_hot_data['y']

# размерность X
num_rows_X, num_columns_X = X.shape
print(f'X: Number of rows = {num_rows_X}, Number of columns = {num_columns_X}')

# рзамерность y
num_rows_y = y.shape[0]
print(f'y: Number of rows = {num_rows_y}')

# деление тестовая/обучающая выборка
X_train, X_test, y_train, y_test = train_test_split(X,y,
                                   random_state=104,
                                   test_size=0.25,
                                   shuffle=True)

# оверсемплинг для повышения точности (увеличение количества редких классов)
smote = RandomOverSampler()
X_resampled, y_resampled = smote.fit_resample(X, y)

# размерность ресемплированных данных
num_rows_X_resampled, num_columns_X_resampled = X_resampled.shape
print(f'X_resampled: Number of rows = {num_rows_X_resampled}, Number of columns = {num_columns_X_resampled}')

num_rows_y_resampled = y_resampled.shape[0]
print(f'y_resampled: Number of rows = {num_rows_y_resampled}')

# деление сглаженных и ресемплированных данных на тестовую/обучаемую выборки
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_resampled, y_resampled,
                                   random_state=42,
                                   test_size=0.25,
                                   shuffle=True)

"""#Selection Model by PyCaret"""

s = ClassificationExperiment()
s.setup(data=one_hot_data, target="y", session_id=1066)
s.compare_models(n_select = 5, sort='Accuracy', fold=5)

"""# Сравнение обучение модели на сбалансированных данных и несбалансированных на примере RandomForest

##Несбалансированные данные
"""

rf = RandomForestClassifier(criterion='gini', max_features='sqrt',
                        n_estimators=100, n_jobs=-1, random_state=1066)
# не оверсемплированные данные
rf.fit(X_train, y_train)
prediction_test = rf.predict(X_test)

print(accuracy_score(y_test, prediction_test))
print(classification_report(y_test, prediction_test))

plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, prediction_test),
                annot=True,fmt = "d",linecolor="k",linewidths=3,cmap="viridis")

plt.title("RF(imbalanced) матрица ошибок",fontsize=12)
plt.show()

"""##Сбалансированные данные"""

rfs = RandomForestClassifier(criterion='gini', max_features='sqrt',
                        n_estimators=100, n_jobs=-1, random_state=1066)
# оверсемплированные (сбалансированные) данные
rfs.fit(X_train_smote, y_train_smote)
prediction_test = rf.predict(X_test_smote)
# print(prediction_test)
print(accuracy_score(y_test_smote, prediction_test))
print(classification_report(y_test_smote, prediction_test))

plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test_smote, prediction_test),
                annot=True,fmt = "d",linecolor="k",linewidths=3)

plt.title("RF(balanced) матрица ошибок",fontsize=14)
plt.show()

y_rfpred_prob = rfs.predict_proba(X_test_smote)[:,1]
fpr_rf, tpr_rf, thresholds = roc_curve(y_test_smote, y_rfpred_prob)
plt.plot([0, 1], [0, 1], 'k--' )
plt.plot(fpr_rf, tpr_rf, label='Random Forest',color = "r")
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('RF ROC Curve',fontsize=16)
plt.show();

# важность фичей
feature_importance = rfs.feature_importances_

# датафрейм важности признаков
feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print(feature_importance_df)