# Модель для кредитного скоринга

Этот проект реализует модель кредитного скоринга с использованием различных методов машинного обучения. Данные загружаются из CSV-файла, после чего проводится предварительная обработка, включающая работу с пропущенными значениями, кодирование категориальных переменных и масштабирование числовых данных. В проекте используются и сравниваются такие модели, как Random Forest, CatBoost, LightGBM, XGBoost и метод опорных векторов (SVM). Также сравнивается производительность моделей на несбалансированных и сбалансированных данных с использованием RandomOverSampler.

## Обзор проекта

### Основные моменты:
- **Предварительная обработка данных**: обработка пропущенных значений, кодирование категориальных данных, масштабирование и удаление выбросов.
- **Анализ данных (EDA)**: визуализации, включая круговые диаграммы, плотностные графики, гистограммы и ящиковые диаграммы.
- **Моделирование**: Сравнение различных моделей машинного обучения с помощью функции `compare_models` из библиотеки PyCaret.
- **Оценка моделей**: точность, отчёты по классификации, матрицы ошибок и ROC-кривые.
- **Сбалансированные и несбалансированные данные**: Сравнение эффективности моделей на сбалансированных данных после применения метода оверсемплинга.

## Фичи
- **PyCaret**: Упрощает и ускоряет процесс сравнения моделей машинного обучения.
- **Одновременное использование Label Encoding и One-Hot Encoding**: Применение разных методов кодирования для различных признаков.
- **Работа с несбалансированными данными**: Включает методы для балансировки классов, такие как RandomOverSampler.
- **Использование нескольких популярных алгоритмов**: Поддержка CatBoost, LightGBM, XGBoost и других.
- **Анализ важности признаков**: Определение значимости каждого признака для интерпретации моделей.

## Установка и запуск

### Установка зависимостей
1. Склонируйте репозиторий с данными:
```
git clone https://github.com/vassert32/credit_scoring
```
2. Установите необходимые зависимости:
```
pip install -r requirements.txt
```

### Запуск проекта
1. Загрузите данные в формате CSV, указав путь в коде проекта (сами данные, "сырые" и готовые для обучения, находятся в директории репозитория с названием "data").
2. Проведите анализ данных и моделирование через Jupyter Notebook или Google Colab.

### Примечание
Проект использует оверсемплинг для балансировки классов в тренировочных данных, что может улучшить результаты моделей на тренировочных этапах. Однако при применении модели на несбалансированных данных метрики могут отличаться, и рекомендуется учитывать реальные характеристики данных при оценке.
